{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, roc_auc_score, hamming_loss, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>non_toxic</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>percent_unique_word_count</th>\n",
       "      <th>percent_upper_case_word_count</th>\n",
       "      <th>percent_punctuation_count</th>\n",
       "      <th>cleaned_comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>4.651163</td>\n",
       "      <td>23.255814</td>\n",
       "      <td>explanation why the edit make under username h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>aww match this background colour seemingly sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>hey man really not try edit war just that this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>72.566372</td>\n",
       "      <td>4.424779</td>\n",
       "      <td>18.584071</td>\n",
       "      <td>more cannot make any real suggestions improvem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>you sir hero any chance you remember what page...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  non_toxic  \\\n",
       "0             0        0       0       0              0          0   \n",
       "1             0        0       0       0              0          0   \n",
       "2             0        0       0       0              0          0   \n",
       "3             0        0       0       0              0          0   \n",
       "4             0        0       0       0              0          0   \n",
       "\n",
       "   word_count  unique_word_count  upper_case_word_count  stop_word_count  \\\n",
       "0          43                 41                      2               20   \n",
       "1          17                 17                      1                3   \n",
       "2          42                 39                      0               21   \n",
       "3         113                 82                      5               58   \n",
       "4          13                 13                      0                6   \n",
       "\n",
       "   punctuation_count  title_word_count  sentence_count  \\\n",
       "0                 10                11               5   \n",
       "1                 12                 3               4   \n",
       "2                  6                 2               4   \n",
       "3                 21                 7               6   \n",
       "4                  5                 2               3   \n",
       "\n",
       "   percent_unique_word_count  percent_upper_case_word_count  \\\n",
       "0                  95.348837                       4.651163   \n",
       "1                 100.000000                       5.882353   \n",
       "2                  92.857143                       0.000000   \n",
       "3                  72.566372                       4.424779   \n",
       "4                 100.000000                       0.000000   \n",
       "\n",
       "   percent_punctuation_count  \\\n",
       "0                  23.255814   \n",
       "1                  70.588235   \n",
       "2                  14.285714   \n",
       "3                  18.584071   \n",
       "4                  38.461538   \n",
       "\n",
       "                                cleaned_comment_text  \n",
       "0  explanation why the edit make under username h...  \n",
       "1  aww match this background colour seemingly sti...  \n",
       "2  hey man really not try edit war just that this...  \n",
       "3  more cannot make any real suggestions improvem...  \n",
       "4  you sir hero any chance you remember what page...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the pickle file\n",
    "\n",
    "with open('../saved_file/after_eda.pickle', 'rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs(feature, pipe, pipe_params, filename):\n",
    "\n",
    "    X = df_train[\"cleaned_comment_text\"]\n",
    "    y = df_train[feature]\n",
    "\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    # gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    with open(f\"../saved_file/{filename}.pickle\", \"wb\") as f:\n",
    "        pickle.dump(gs, f)\n",
    "\n",
    "    # y_pred = gs.predict(X_test)\n",
    "\n",
    "    # # accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # ConfusionMatrixDisplay(\n",
    "    #     confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=[\"0\", \"1\"]\n",
    "    # ).plot(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "tfidf_log_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('lg', LogisticRegression())\n",
    "])\n",
    "\n",
    "tfidf_svc_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('svc', LinearSVC())\n",
    "])\n",
    "\n",
    "tfidf_nb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('nb', ComplementNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "tfidf_log_params = {\n",
    "    'tfidf__max_features': [2000, 3000, 5000],\n",
    "    'tfidf__min_df': [2, 3],\n",
    "    'tfidf__max_df': [.9, .95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'lg__solver': ['liblinear'],\n",
    "    'lg__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'lg__penalty': ['l1', 'l2'],\n",
    "    'lg__max_iter': [1000,2000],\n",
    "    'lg__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "tfidf_svc_params = {\n",
    "    'tfidf__max_features': [2000, 3000, 5000],\n",
    "    'tfidf__min_df': [2, 3],\n",
    "    'tfidf__max_df': [.9, .95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'svc__C': [0.01,0.1 ,1, 10, 100],\n",
    "    'svc__max_iter': [10_000],\n",
    "    # 'svc__dual':[False],\n",
    "    'svc__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "tfidf_nb_params = {\n",
    "    'tfidf__max_features': [2000, 3000, 5000],\n",
    "    'tfidf__min_df': [2, 3],\n",
    "    'tfidf__max_df': [.9, .95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'nb__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_models = {\n",
    "    'toxic': 'toxic_tfidf_log',\n",
    "    'severe_toxic' : 'severe_toxic_tfidf_log',\n",
    "    'obscene' : 'obscene_tfidf_log',\n",
    "    'threat' : 'threat_tfidf_log',\n",
    "    'insult' : 'insult_tfidf_log',\n",
    "    'identity_hate' : 'identity_hate_tfidf_log'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_models = {\n",
    "    'toxic': 'toxic_tfidf_nb',\n",
    "    'severe_toxic' : 'severe_toxic_tfidf_nb',\n",
    "    'obscene' : 'obscene_tfidf_nb',\n",
    "    'threat' : 'threat_tfidf_nb',\n",
    "    'insult' : 'insult_tfidf_nb',\n",
    "    'identity_hate' : 'identity_hate_tfidf_nb'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_models = {\n",
    "    'toxic': 'toxic_tfidf_svc',\n",
    "    'severe_toxic' : 'severe_toxic_tfidf_svc',\n",
    "    'obscene' : 'obscene_tfidf_svc',\n",
    "    'threat' : 'threat_tfidf_svc',\n",
    "    'insult' : 'insult_tfidf_svc',\n",
    "    'identity_hate' : 'identity_hate_tfidf_svc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in svc_models.items():\n",
    "    gs(feature=k, pipe=tfidf_svc_pipe, pipe_params=tfidf_svc_params, filename=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in log_models.items():\n",
    "    gs(feature=k, pipe=tfidf_log_pipe, pipe_params=tfidf_log_params, filename=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in nb_models.items():\n",
    "    gs(feature=k, pipe=tfidf_nb_pipe, pipe_params=tfidf_nb_params, filename=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to plot confusion matrix and obtain the metrics into a dataframe\n",
    "\n",
    "# def results_extraction(model_name=\"\"):\n",
    "\n",
    "#     '''\n",
    "#     Function to extract the pickle-ed model and to conduct predictions with X_test, saving the final results to a separate dataframe\n",
    "#     '''\n",
    "    \n",
    "#     filename = f'./model_results/{model_name}_trained.pickle'\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         model = pickle.load(f)\n",
    "\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "#     ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=['learnpython', 'learnmachinelearning']).plot(cmap='Blues')\n",
    "\n",
    "#     # 0 is python, 1 is ml\n",
    "#     plt.title(f'{model_name}: Confusion Matrix')\n",
    "#     plt.savefig(f\"./confusion_matrix/{model_name}_confusion_matrix.png\", bbox_inches='tight', facecolor='w')\n",
    "#     plt.close()\n",
    "\n",
    "#     # Different metrics\n",
    "#     accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "#     misclassification = 1 - accuracy\n",
    "#     recall = tp / (tp + fn)\n",
    "#     specificity = tn / (tn + fp)\n",
    "#     precision = tp / (tp + fp)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#     acc_diff = np.abs((model.score(X_train, y_train) - model.score(X_test, y_test))) / model.score(X_train, y_train)\n",
    "\n",
    "#     # Metrics for roc curve and auc\n",
    "#     pred_prob = model.predict_proba(X_test)\n",
    "#     train_prob = model.predict_proba(X_train)\n",
    "\n",
    "#     # fpr, tpr, thresh = roc_curve(y_test, pred_prob[:,1], pos_label=1)\n",
    "#     pred_auc_score = roc_auc_score(y_test, pred_prob[:,1])\n",
    "#     train_auc_score = roc_auc_score(y_train, train_prob[:,1])\n",
    "#     auc_diff = np.abs((train_auc_score - pred_auc_score)) / train_auc_score\n",
    "\n",
    "#     # Append all above results to 'results' dictionary\n",
    "#     results[model_name] = [\n",
    "#         # model.best_params_,\n",
    "#         model.score(X_train, y_train),\n",
    "#         model.score(X_test, y_test),\n",
    "#         misclassification,\n",
    "#         recall,\n",
    "#         specificity,\n",
    "#         precision,\n",
    "#         f1,\n",
    "#         train_auc_score,\n",
    "#         pred_auc_score,\n",
    "#         auc_diff,\n",
    "#         acc_diff\n",
    "#     ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d55a5cfa455d22174465b36fe05f18472c994ecfaf24a5ba224876a16aca7740"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
